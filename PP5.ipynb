{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46PjFLL0_lYC",
        "outputId": "3655debb-3027-4f47-f6aa-5a444f7a9277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-oz_zrjqu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-oz_zrjqu\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4304 sha256=824ba3b6fad041d013ff51de9664907a1c640ab2ca4acaa223a8734575b11f0f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kkpbfy67/wheels/f3/08/cc/e2b5b0e1c92df07dbb50a6f024a68ce090f5e7b2316b41756d\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n",
            "Copying samples to /root/NVIDIA_CUDA-11.2_Samples now...\n",
            "Finished copying samples.\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/cuda/bin/nvcc --version\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "!cuda-install-samples-11.2.sh ~ && cd /root/NVIDIA_CUDA-11.2_Samples/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "duxRpg6P_f4R",
        "outputId": "c77e7356-0463-415a-bd1c-92b0c5367b4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/curand.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "%%cuda --name curand.cu\n",
        "#include <time.h>\n",
        "#include <curand.h>\n",
        "#include <cublas_v2.h>\n",
        "#include <curand_kernel.h>\n",
        "#include <iostream>\n",
        "#pragma comment (lib, \"cublas.lib\")\n",
        "#pragma comment (lib, \"curand.lib\")\n",
        "\n",
        "\n",
        "#define IDX2C(i,j,ld) (((j)*(ld))+(i))\n",
        "\n",
        "// Функция случайной генерации матрицы на GPU\n",
        "void GPU_fill_rand(float* A, int nr_rows_A, int nr_cols_A) {\n",
        "    // Create a pseudo-random number generator\n",
        "    curandGenerator_t prng;\n",
        "    curandCreateGenerator(&prng, CURAND_RNG_PSEUDO_DEFAULT);\n",
        "    \n",
        "    // Set the seed for the random number generator using the system clock\n",
        "    curandSetPseudoRandomGeneratorSeed(prng, (unsigned long long) clock());\n",
        "\n",
        "    // Fill the array with random numbers on the device\n",
        "    curandGenerateUniform(prng, A, nr_rows_A * nr_cols_A);\n",
        "}\n",
        "\n",
        "\n",
        "// Multiply the arrays A and B on GPU and save the result in C\n",
        "// C(m,n) = A(m,k) * B(k,n)\n",
        "void gpu_blas_mmul(const float* A, const float* B, float* C, const int m, const int k, const int n) {\n",
        "    int lda = m, ldb = k, ldc = n;\n",
        "    const float alf = 1;\n",
        "    const float bet = 0;\n",
        "    const float* alpha = &alf;\n",
        "    const float* beta = &bet;\n",
        "    \n",
        "    // Create a handle for CUBLAS\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "    \n",
        "    // Do the actual multiplication\n",
        "    cublasSgemm(handle, CUBLAS_OP_T, CUBLAS_OP_T, m, n, k, alpha, A, lda, B, ldb, beta, C, ldc);\n",
        "    //(cublasHandle_t handle, cublasOperation_t transa, cublasOperation_t transb, int m, int n, int k, const TYPE *alpha, \n",
        "    // const TYPE *A, int lda, const TYPE *B, int ldb, const TYPE *beta, TYPE *C, int ldc);\n",
        "    \n",
        "    // Destroy the handle\n",
        "    cublasDestroy(handle);\n",
        "}\n",
        "\n",
        "//Функция для вывода матрицы\n",
        "void print_matrix(float* matrix, int rows, int cols) {\n",
        "    for (int i = 0; i < rows; ++i) {\n",
        "        for (int j = 0; j < cols; ++j) {\n",
        "            printf(\"%f \", matrix[j * rows + i]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "//Последовательная программа\n",
        "// C(m,n) = A(m,k) * B(k,n)\n",
        "void consistent(const float* A, const float* B, float*C, const int m, const int k, const int n) {\n",
        "    for (int i = 0; i < m; ++i) {\n",
        "        for (int j = 0; j < n; ++j) {\n",
        "            C[IDX2C(i, j, n)] = 0.0;\n",
        "            for (int r = 0; r < n; ++r) {\n",
        "                C[IDX2C(i, j, n)] += A[IDX2C(i, r, k)] * B[IDX2C(r, j, n)];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "    // Allocate 3 arrays on CPU\n",
        "    int nr_rows_A, nr_cols_A, nr_rows_B, nr_cols_B, nr_rows_C, nr_cols_C;\n",
        "    // for simplicity we are going to use square arrays\n",
        "    nr_rows_A = nr_cols_A = nr_rows_B = nr_cols_B = nr_rows_C = nr_cols_C = 256;\n",
        "    \n",
        "    float* h_A = (float*)malloc(nr_rows_A * nr_cols_A * sizeof(float));\n",
        "    float* h_B = (float*)malloc(nr_rows_B * nr_cols_B * sizeof(float));\n",
        "    float* h_C = (float*)malloc(nr_rows_C * nr_cols_C * sizeof(float));\n",
        "    printf(\"Var8\\n\");\n",
        "    double begin = clock();\n",
        "    \n",
        "    for (int i = 0; i < nr_rows_A * nr_rows_A; i++) {\n",
        "\t\th_A[i] = (float)rand();\n",
        "\t\th_B[i] = (float)rand();\n",
        "\t}\n",
        "  \n",
        "    // Allocate 3 arrays on GPU\n",
        "    float* d_A, * d_B, * d_C;\n",
        "    \n",
        "\n",
        "    cudaMalloc(&d_A, nr_rows_A * nr_cols_A * sizeof(float));\n",
        "    cudaMalloc(&d_B, nr_rows_B * nr_cols_B * sizeof(float));\n",
        "    cudaMalloc(&d_C, nr_rows_C * nr_cols_C * sizeof(float));\n",
        "       \n",
        "\n",
        "    // Optionally we can copy the data back on CPU and print the arrays\n",
        "  cudaMemcpy(d_A, h_A, nr_rows_A * nr_cols_A*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_B, h_B, nr_rows_B * nr_cols_B*sizeof(float), cudaMemcpyHostToDevice);\n",
        "    \n",
        "\n",
        "// Multiply A and B on GPU\n",
        "    //double time_g = 0.0;\n",
        "    //    srand(time(0));\n",
        "    double begin1 = clock();\n",
        "    gpu_blas_mmul(d_A, d_B, d_C, nr_rows_A, nr_cols_A, nr_cols_B);\n",
        "    double end = (clock() - begin) / CLOCKS_PER_SEC;\n",
        "    printf(\"\\nTime1 : %f\\n\", end);\n",
        "    \n",
        "    \n",
        "    //последовательная:\n",
        "    double time_c = 0.0;\n",
        "    //for (int step = 0; step < 12; ++step) {\n",
        "        srand(time(0));\n",
        "        double begin2 = clock();\n",
        "        consistent(h_A, h_B, h_C, nr_rows_A, nr_cols_A, nr_cols_B);\n",
        "        double end2 = double(clock() - begin2) / CLOCKS_PER_SEC;\n",
        "        time_c += end2;\n",
        "    //}\n",
        "    \n",
        "    printf(\"\\nTime of consistent programm: %f\\n\", time_c);\n",
        "    //std::cout << \"C by consistent programm:\" << std::endl;\n",
        "    //print_matrix(h_C, nr_rows_C, nr_cols_C);\n",
        "    // Copy (and print) the result on host memory\n",
        "    //cudaMemcpy(h_C, d_C, nr_rows_C * nr_cols_C * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    //printf(\"\\nTime of CUDA programm: %f\\n\", end);\n",
        "    //std::cout << \"C by CUDA program:\" << std::endl;\n",
        "    //print_matrix(h_C, nr_rows_C, nr_cols_C);\n",
        "\n",
        "    //Free GPU memory\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    // Free CPU memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g37cNZYk_rM1"
      },
      "outputs": [],
      "source": [
        "\n",
        "!nvcc -o /content/src/curand /content/src/curand.cu -lcurand -lcublas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIiN7O2V_81X",
        "outputId": "16f48132-02ea-45cf-d517-6c65ffe304eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Var8\n",
            "\n",
            "Time1 : 1.132654\n",
            "\n",
            "Time of consistent programm: 0.085006\n"
          ]
        }
      ],
      "source": [
        "!/content/src/curand\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Rhr5R_6IUsZk",
        "outputId": "91b747bf-9425-4ad1-fdf1-35d4b9587c91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/curand1.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "%%cuda --name curand1.cu\n",
        "#include <time.h>\n",
        "#include <curand.h>\n",
        "#include <cublas_v2.h>\n",
        "#include <curand_kernel.h>\n",
        "#include <iostream>\n",
        "#pragma comment (lib, \"cublas.lib\")\n",
        "#pragma comment (lib, \"curand.lib\")\n",
        "\n",
        "\n",
        "#define IDX2C(i,j,ld) (((j)*(ld))+(i))\n",
        "\n",
        "// Функция случайной генерации матрицы на GPU\n",
        "void GPU_fill_rand(float* A, int nr_rows_A, int nr_cols_A) {\n",
        "    // Create a pseudo-random number generator\n",
        "    curandGenerator_t prng;\n",
        "    curandCreateGenerator(&prng, CURAND_RNG_PSEUDO_DEFAULT);\n",
        "    \n",
        "    // Set the seed for the random number generator using the system clock\n",
        "    curandSetPseudoRandomGeneratorSeed(prng, (unsigned long long) clock());\n",
        "\n",
        "    // Fill the array with random numbers on the device\n",
        "    curandGenerateUniform(prng, A, nr_rows_A * nr_cols_A);\n",
        "}\n",
        "\n",
        "\n",
        "// Multiply the arrays A and B on GPU and save the result in C\n",
        "// C(m,n) = A(m,k) * B(k,n)\n",
        "void gpu_blas_mmul(const float* A, const float* B, float* C, const int m, const int k, const int n) {\n",
        "    int lda = m, ldb = k, ldc = n;\n",
        "    const float alf = 1;\n",
        "    const float bet = 0;\n",
        "    const float* alpha = &alf;\n",
        "    const float* beta = &bet;\n",
        "    \n",
        "    // Create a handle for CUBLAS\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "    \n",
        "    // Do the actual multiplication\n",
        "    cublasSgemm(handle, CUBLAS_OP_T, CUBLAS_OP_T, m, n, k, alpha, A, lda, B, ldb, beta, C, ldc);\n",
        "    //(cublasHandle_t handle, cublasOperation_t transa, cublasOperation_t transb, int m, int n, int k, const TYPE *alpha, \n",
        "    // const TYPE *A, int lda, const TYPE *B, int ldb, const TYPE *beta, TYPE *C, int ldc);\n",
        "    \n",
        "    // Destroy the handle\n",
        "    cublasDestroy(handle);\n",
        "}\n",
        "\n",
        "//Функция для вывода матрицы\n",
        "void print_matrix(float* matrix, int rows, int cols) {\n",
        "    for (int i = 0; i < rows; ++i) {\n",
        "        for (int j = 0; j < cols; ++j) {\n",
        "            printf(\"%f \", matrix[j * rows + i]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "//Последовательная программа\n",
        "// C(m,n) = A(m,k) * B(k,n)\n",
        "void consistent(const float* A, const float* B, float*C, const int m, const int k, const int n) {\n",
        "    for (int i = 0; i < m; ++i) {\n",
        "        for (int j = 0; j < n; ++j) {\n",
        "            C[IDX2C(i, j, n)] = 0.0;\n",
        "            for (int r = 0; r < n; ++r) {\n",
        "                C[IDX2C(i, j, n)] += A[IDX2C(i, r, k)] * B[IDX2C(r, j, n)];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "//float, (256, 1024, 4096), (с Т, c Т) \n",
        "//тип,размерность матриц (матрицы квадратные), показатель транспонирования матриц.\n",
        "int main() {\n",
        "    \n",
        "    printf(\"Вариант 8\\n\");\n",
        "    // Allocate 3 arrays on CPU\n",
        "    int nr_rows_A, nr_cols_A, nr_rows_B, nr_cols_B, nr_rows_C, nr_cols_C;\n",
        "    \n",
        "    // for simplicity we are going to use square arrays\n",
        "    //nr_rows_A = nr_cols_A =nr_rows_B = nr_cols_B=nr_rows_C = nr_cols_C= 256;\n",
        "    //nr_rows_A = nr_cols_A=nr_rows_B = nr_cols_B =nr_rows_C = nr_cols_C= 1024;\n",
        "    nr_rows_A = nr_cols_A=nr_rows_B = nr_cols_B=nr_rows_C = nr_cols_C = 4096;\n",
        "    \n",
        "    float* h_A = (float*)malloc(nr_rows_A * nr_cols_A * sizeof(float));\n",
        "    float* h_B = (float*)malloc(nr_rows_B * nr_cols_B * sizeof(float));\n",
        "    float* h_C = (float*)malloc(nr_rows_C * nr_cols_C * sizeof(float));\n",
        "    \n",
        "\n",
        "    // Allocate 3 arrays on GPU\n",
        "    float* d_A, * d_B, * d_C;\n",
        "    cudaMalloc(&d_A, nr_rows_A * nr_cols_A * sizeof(float));\n",
        "    cudaMalloc(&d_B, nr_rows_B * nr_cols_B * sizeof(float));\n",
        "    cudaMalloc(&d_C, nr_rows_C * nr_cols_C * sizeof(float));\n",
        "    \n",
        "      \n",
        "\n",
        "    // Multiply A and B on GPU\n",
        "    double time_g = 0.0;\n",
        "    double begin = clock();\n",
        "    GPU_fill_rand(d_A, nr_rows_A, nr_cols_A);\n",
        "    GPU_fill_rand(d_B, nr_rows_B, nr_cols_B);\n",
        "   \n",
        "    // Optionally we can copy the data back on CPU and print the arrays\n",
        "    cudaMemcpy(h_A, d_A, nr_rows_A * nr_cols_A * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(h_B, d_B, nr_rows_B * nr_cols_B * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    //cudaMemcpy(d_A, h_A, nr_rows_A * nr_cols_A * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    //cudaMemcpy(d_B, h_B, nr_rows_B * nr_cols_B * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "    \n",
        "    gpu_blas_mmul(d_A, d_B, d_C, nr_rows_A, nr_cols_A, nr_cols_B);\n",
        "    double end = (clock() - begin) / CLOCKS_PER_SEC;\n",
        "    //time_g += end;\n",
        "    //}\n",
        "    \n",
        "    // Copy (and print) the result on host memory\n",
        "    cudaMemcpy(h_C, d_C, nr_rows_C * nr_cols_C * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    printf(\"\\nTime of CUDA programm: %f\\n\", end);\n",
        "    \n",
        "    //std::cout << \"C by CUDA program:\" << std::endl;\n",
        "    //print_matrix(h_C, nr_rows_C, nr_cols_C);\n",
        "\n",
        "\n",
        "    int T=12;\n",
        "    //последовательная реализация\n",
        "    /*double time_c = 0.0;\n",
        "    for (int t = 0; t < T; t++) {\n",
        "        srand(time(0));\n",
        "        double begin = clock();\n",
        "        consistent(h_A, h_B, h_C, nr_rows_A, nr_cols_A, nr_cols_B);\n",
        "        double end = double(clock() - begin) / CLOCKS_PER_SEC;\n",
        "        time_c += end;\n",
        "    }\n",
        "    printf(\"\\nTime of consistent programm: %f\\n\", time_c / T);*/\n",
        "    //std::cout << \"C by consistent programm:\" << std::endl;\n",
        "    //print_matrix(h_C, nr_rows_C, nr_cols_C);\n",
        "\n",
        "\n",
        "    //Free GPU memory\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    // Free CPU memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o /content/src/curand1 /content/src/curand1.cu -lcurand -lcublas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmQdS1ta-oab",
        "outputId": "19dbafad-b33a-47cf-ae65-b639e0896616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/src/curand1.cu(102): warning: variable \"time_g\" was declared but never referenced\n",
            "\n",
            "/content/src/curand1.cu(130): warning: variable \"T\" was declared but never referenced\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/curand1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTW7mdrQ-npc",
        "outputId": "0bb1d1f2-a0c9-4a0a-e5ac-b94c375a352f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вариант 8\n",
            "\n",
            "Time of CUDA programm: 0.669311\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLb70UUCFdF9tgKaYKGKUb"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}